{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bCvxBB2xrlET"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from torch.utils.data import DataLoader\n",
        "import torch\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "from torch.autograd import Variable"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download target NR quality metric model"
      ],
      "metadata": {
        "id": "J_zXx4xbE87p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# download the model\n",
        "!wget -O RoIPoolModel.pth -N https://github.com/baidut/PaQ-2-PiQ/releases/download/v1.0/RoIPoolModel-fit.10.bs.120.pth\n",
        "\n",
        "# download a test image\n",
        "!wget -N https://github.com/baidut/PaQ-2-PiQ/releases/download/v1.0/Picture1.jpg\n",
        "\n",
        "# download the standalone version of code\n",
        "!wget -N https://raw.githubusercontent.com/baidut/PaQ-2-PiQ_GAE/master/paq2piq_standalone.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ff7-2bsrvi_",
        "outputId": "e32369a6-045e-44b2-8dc3-5efaae7af0ee"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: timestamping does nothing in combination with -O. See the manual\n",
            "for details.\n",
            "\n",
            "--2023-09-09 08:35:58--  https://github.com/baidut/PaQ-2-PiQ/releases/download/v1.0/RoIPoolModel-fit.10.bs.120.pth\n",
            "Resolving github.com (github.com)... 140.82.121.4\n",
            "Connecting to github.com (github.com)|140.82.121.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/237024974/a1c42500-4755-11ea-9c0e-7bf2246fe9e5?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230909%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230909T083558Z&X-Amz-Expires=300&X-Amz-Signature=fa9e3a561be5f79bdf0a300c5550ba858b5adf411b3cbe2ac37cc74e141a85af&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=237024974&response-content-disposition=attachment%3B%20filename%3DRoIPoolModel-fit.10.bs.120.pth&response-content-type=application%2Foctet-stream [following]\n",
            "--2023-09-09 08:35:58--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/237024974/a1c42500-4755-11ea-9c0e-7bf2246fe9e5?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230909%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230909T083558Z&X-Amz-Expires=300&X-Amz-Signature=fa9e3a561be5f79bdf0a300c5550ba858b5adf411b3cbe2ac37cc74e141a85af&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=237024974&response-content-disposition=attachment%3B%20filename%3DRoIPoolModel-fit.10.bs.120.pth&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 140552190 (134M) [application/octet-stream]\n",
            "Saving to: ‘RoIPoolModel.pth’\n",
            "\n",
            "RoIPoolModel.pth    100%[===================>] 134.04M  48.7MB/s    in 2.8s    \n",
            "\n",
            "2023-09-09 08:36:01 (48.7 MB/s) - ‘RoIPoolModel.pth’ saved [140552190/140552190]\n",
            "\n",
            "--2023-09-09 08:36:01--  https://github.com/baidut/PaQ-2-PiQ/releases/download/v1.0/Picture1.jpg\n",
            "Resolving github.com (github.com)... 140.82.121.3\n",
            "Connecting to github.com (github.com)|140.82.121.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/237024974/b488b880-6231-11ea-8328-cd6123862fda?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230909%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230909T083601Z&X-Amz-Expires=300&X-Amz-Signature=f58b14dd327f2f292c485935d8dbdf2c1addfb9f4d88477a965249f242d2ec94&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=237024974&response-content-disposition=attachment%3B%20filename%3DPicture1.jpg&response-content-type=application%2Foctet-stream [following]\n",
            "--2023-09-09 08:36:01--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/237024974/b488b880-6231-11ea-8328-cd6123862fda?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230909%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230909T083601Z&X-Amz-Expires=300&X-Amz-Signature=f58b14dd327f2f292c485935d8dbdf2c1addfb9f4d88477a965249f242d2ec94&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=237024974&response-content-disposition=attachment%3B%20filename%3DPicture1.jpg&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.109.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 110901 (108K) [application/octet-stream]\n",
            "Saving to: ‘Picture1.jpg’\n",
            "\n",
            "Picture1.jpg        100%[===================>] 108.30K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2023-09-09 08:36:01 (14.8 MB/s) - ‘Picture1.jpg’ saved [110901/110901]\n",
            "\n",
            "--2023-09-09 08:36:01--  https://raw.githubusercontent.com/baidut/PaQ-2-PiQ_GAE/master/paq2piq_standalone.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6486 (6.3K) [text/plain]\n",
            "Saving to: ‘paq2piq_standalone.py’\n",
            "\n",
            "paq2piq_standalone. 100%[===================>]   6.33K  --.-KB/s    in 0s      \n",
            "\n",
            "Last-modified header missing -- time-stamps turned off.\n",
            "2023-09-09 08:36:02 (70.5 MB/s) - ‘paq2piq_standalone.py’ saved [6486/6486]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1XpA1KPuMVY",
        "outputId": "94ac2f24-7cf6-4e31-e2e9-95170aa9ee25"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from paq2piq_standalone import *\n",
        "from torch.autograd import Variable\n",
        "import imageio\n",
        "import os\n",
        "import subprocess\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "cyvvPQaDuOR7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bc1bac3-3c21-4441-911a-d92c0dc181db"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/paq2piq_standalone.py:46: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "  if backbone is 'resnet18':\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_NET_MEAN = [0.485, 0.456, 0.406]\n",
        "IMAGE_NET_STD = [0.229, 0.224, 0.225]\n",
        "\n",
        "\n",
        "class Transform:\n",
        "    def __init__(self):\n",
        "        # normalize = transforms.Normalize(mean=IMAGE_NET_MEAN, std=IMAGE_NET_STD)\n",
        "\n",
        "        self._train_transform = transforms.Compose(\n",
        "            [\n",
        "                transforms.ToTensor(),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        self._val_transform = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "    @property\n",
        "    def train_transform(self):\n",
        "        return self._train_transform\n",
        "\n",
        "    @property\n",
        "    def val_transform(self):\n",
        "        return self._val_transform"
      ],
      "metadata": {
        "id": "BtFlU86SuQsW"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_state = torch.load('RoIPoolModel.pth', map_location=lambda storage, loc: storage)\n",
        "model = RoIPoolModel()\n",
        "model.load_state_dict(model_state[\"model\"])\n",
        "model = model.to(device)\n",
        "transform = Transform().val_transform\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cTlFqZuuTJY",
        "outputId": "5eee321a-ee8e-4748-bdd7-289291351470"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RoIPoolModel(\n",
              "  (body): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    (4): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (5): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (6): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (7): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (head): Sequential(\n",
              "    (0): AdaptiveConcatPool2d(\n",
              "      (ap): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "      (mp): AdaptiveMaxPool2d(output_size=(1, 1))\n",
              "    )\n",
              "    (1): Flatten(start_dim=1, end_dim=-1)\n",
              "    (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (3): Dropout(p=0.25, inplace=False)\n",
              "    (4): Linear(in_features=1024, out_features=512, bias=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (7): Dropout(p=0.5, inplace=False)\n",
              "    (8): Linear(in_features=512, out_features=1, bias=True)\n",
              "  )\n",
              "  (roi_pool): RoIPool(output_size=(2, 2), spatial_scale=0.03125)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Attack training code"
      ],
      "metadata": {
        "id": "KewqdcoeFI6g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.autograd import Variable\n",
        "import cv2\n",
        "import numpy as np\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "from torch import optim\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "import imageio\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "import numpy as np\n",
        "from torchvision import transforms\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from torch.utils.data import Dataset\n",
        "from typing import Optional\n",
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "from torchvision import transforms\n",
        "import random\n",
        "#import albumentations as A"
      ],
      "metadata": {
        "id": "9nG48CPZuVcj"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def center_crop(image):\n",
        "  center = image.shape[0] / 2, image.shape[1] / 2\n",
        "  if center[1] < 256 or center[0] < 256:\n",
        "    return cv2.resize(image, (256, 256))\n",
        "  x = center[1] - 128\n",
        "  y = center[0] - 128\n",
        "\n",
        "  return image[int(y):int(y+256), int(x):int(x+256)]"
      ],
      "metadata": {
        "id": "cuMNrMTtucXs"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyCustomDataset(Dataset):\n",
        "    def __init__(self,\n",
        "                 path_gt,\n",
        "                 mode\n",
        "                ):\n",
        "\n",
        "        self._items = []\n",
        "        self._index = 0\n",
        "        self.mode = mode\n",
        "        if mode == 'train':\n",
        "          dir_img = sorted(os.listdir(path_gt))\n",
        "        else:\n",
        "          dir_img = sorted(os.listdir(path_gt))\n",
        "        img_pathes = dir_img\n",
        "\n",
        "        for img_path in img_pathes:\n",
        "          self._items.append((\n",
        "            os.path.join(path_gt, img_path)\n",
        "          ))\n",
        "        random.shuffle(self._items)\n",
        "\n",
        "    def __len__(self):\n",
        "      return len(self._items)\n",
        "\n",
        "    def next_data(self):\n",
        "      gt_path = self._items[self._index]\n",
        "      self._index += 1\n",
        "      if self._index == len(self._items):\n",
        "        self._index = 0\n",
        "        random.shuffle(self._items)\n",
        "\n",
        "      image = Image.open(gt_path).convert('RGB')\n",
        "      image = np.array(image).astype(np.float32)\n",
        "      image = center_crop(image)\n",
        "      #if self.mode=='train':\n",
        "      #  transformed = my_transform(image=image)\n",
        "      #  image = transformed[\"image\"]\n",
        "\n",
        "      image = image / 255.\n",
        "      image = transforms.ToTensor()(image)\n",
        "      #image = image.unsqueeze_(0)\n",
        "      y = image.to(device)\n",
        "      return y\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "      gt_path = self._items[index]\n",
        "      image = Image.open(gt_path).convert('RGB')\n",
        "      image = np.array(image).astype(np.float32)\n",
        "\n",
        "      image = center_crop(image)\n",
        "\n",
        "      #if self.mode=='train':\n",
        "      #transformed = my_transform(image=image)\n",
        "      #image = transformed[\"image\"]\n",
        "\n",
        "      image = image / 255.\n",
        "      image = transforms.ToTensor()(image)\n",
        "      y = image.to(device)\n",
        "      return y"
      ],
      "metadata": {
        "id": "T_JaJYsZucuH"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.001\n",
        "eps = 10/255\n",
        "path_train = '/content/drive/MyDrive/metrics/train'\n",
        "path_test = '/content/drive/MyDrive/metrics/val'\n",
        "\n",
        "universal_noise = torch.zeros((1, 3, 256, 256)).to(device)\n",
        "universal_noise = Variable(universal_noise, requires_grad=True)\n",
        "\n",
        "ds_train = MyCustomDataset(path_gt=path_train, mode='train')\n",
        "ds_val = MyCustomDataset(path_gt=path_test, mode='test')\n",
        "dl_train = DataLoader(ds_train, batch_size=1, shuffle=True)\n",
        "dl_val = DataLoader(ds_val, batch_size=1, shuffle=False)\n",
        "n_epoch = 10\n",
        "\n",
        "for epoch in range(n_epoch):\n",
        "  print(epoch)\n",
        "  loss = []\n",
        "  for u in tqdm(range(len(dl_train))):\n",
        "    y = next(iter(dl_train))\n",
        "    res = y + universal_noise\n",
        "    res.data.clamp_(min=0.,max=1.)\n",
        "    a = 1 - model(res).mean() / 100\n",
        "    loss.append(a.item())\n",
        "    a.backward()\n",
        "    delta = universal_noise.grad.clone()\n",
        "    universal_noise.grad.data.zero_()\n",
        "    universal_noise = universal_noise - delta\n",
        "    universal_noise.data.clamp_(min=-eps, max=eps)\n",
        "    universal_noise = Variable(universal_noise, requires_grad=True)\n",
        "  print(abs(universal_noise).mean())\n",
        "  print(np.array(loss).mean())\n",
        "  res_image = (universal_noise + 0.5).data.clamp_(min=0, max=1)\n",
        "  res_img = (res_image.squeeze().data.cpu().numpy().transpose(1, 2, 0) * 255).astype('uint8')\n",
        "  imageio.imwrite(\"/content/drive/MyDrive/metrics/up_methods/cumul/paq2piq\"+f'/pic{epoch:03}.png', res_img)"
      ],
      "metadata": {
        "id": "g4l21IlCuiYg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FRXQ-bN4HTgH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}