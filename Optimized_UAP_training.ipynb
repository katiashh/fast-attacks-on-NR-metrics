{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-8iv6N-kZXFY"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from torch.utils.data import DataLoader\n",
        "import torch\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "from torch.autograd import Variable"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download target NR quality metric model"
      ],
      "metadata": {
        "id": "SB4bCnrODAUR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4ZhMa32ZjO6",
        "outputId": "ee4f6b6d-16a1-4aeb-de19-5add4887f225"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: timestamping does nothing in combination with -O. See the manual\n",
            "for details.\n",
            "\n",
            "--2023-09-09 08:27:54--  https://github.com/baidut/PaQ-2-PiQ/releases/download/v1.0/RoIPoolModel-fit.10.bs.120.pth\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/237024974/a1c42500-4755-11ea-9c0e-7bf2246fe9e5?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230909%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230909T082754Z&X-Amz-Expires=300&X-Amz-Signature=aa659a91a6786545a6dc702282e27b6a42e81a9d3f58ca331a4a07178df882f9&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=237024974&response-content-disposition=attachment%3B%20filename%3DRoIPoolModel-fit.10.bs.120.pth&response-content-type=application%2Foctet-stream [following]\n",
            "--2023-09-09 08:27:54--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/237024974/a1c42500-4755-11ea-9c0e-7bf2246fe9e5?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230909%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230909T082754Z&X-Amz-Expires=300&X-Amz-Signature=aa659a91a6786545a6dc702282e27b6a42e81a9d3f58ca331a4a07178df882f9&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=237024974&response-content-disposition=attachment%3B%20filename%3DRoIPoolModel-fit.10.bs.120.pth&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 140552190 (134M) [application/octet-stream]\n",
            "Saving to: ‘RoIPoolModel.pth’\n",
            "\n",
            "RoIPoolModel.pth    100%[===================>] 134.04M   145MB/s    in 0.9s    \n",
            "\n",
            "2023-09-09 08:27:55 (145 MB/s) - ‘RoIPoolModel.pth’ saved [140552190/140552190]\n",
            "\n",
            "--2023-09-09 08:27:55--  https://github.com/baidut/PaQ-2-PiQ/releases/download/v1.0/Picture1.jpg\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/237024974/b488b880-6231-11ea-8328-cd6123862fda?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230909%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230909T082756Z&X-Amz-Expires=300&X-Amz-Signature=2f4a03eb25a9a17631b1ace3473917c0475008f94f86979300686d6923a6657b&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=237024974&response-content-disposition=attachment%3B%20filename%3DPicture1.jpg&response-content-type=application%2Foctet-stream [following]\n",
            "--2023-09-09 08:27:56--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/237024974/b488b880-6231-11ea-8328-cd6123862fda?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230909%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230909T082756Z&X-Amz-Expires=300&X-Amz-Signature=2f4a03eb25a9a17631b1ace3473917c0475008f94f86979300686d6923a6657b&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=237024974&response-content-disposition=attachment%3B%20filename%3DPicture1.jpg&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 110901 (108K) [application/octet-stream]\n",
            "Saving to: ‘Picture1.jpg’\n",
            "\n",
            "Picture1.jpg        100%[===================>] 108.30K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2023-09-09 08:27:56 (32.0 MB/s) - ‘Picture1.jpg’ saved [110901/110901]\n",
            "\n",
            "--2023-09-09 08:27:56--  https://raw.githubusercontent.com/baidut/PaQ-2-PiQ_GAE/master/paq2piq_standalone.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6486 (6.3K) [text/plain]\n",
            "Saving to: ‘paq2piq_standalone.py’\n",
            "\n",
            "paq2piq_standalone. 100%[===================>]   6.33K  --.-KB/s    in 0s      \n",
            "\n",
            "Last-modified header missing -- time-stamps turned off.\n",
            "2023-09-09 08:27:56 (58.8 MB/s) - ‘paq2piq_standalone.py’ saved [6486/6486]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# download the model\n",
        "!wget -O RoIPoolModel.pth -N https://github.com/baidut/PaQ-2-PiQ/releases/download/v1.0/RoIPoolModel-fit.10.bs.120.pth\n",
        "\n",
        "# download a test image\n",
        "!wget -N https://github.com/baidut/PaQ-2-PiQ/releases/download/v1.0/Picture1.jpg\n",
        "\n",
        "# download the standalone version of code\n",
        "!wget -N https://raw.githubusercontent.com/baidut/PaQ-2-PiQ_GAE/master/paq2piq_standalone.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aEfyW7TBZqlz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4dd0529-2e99-46b1-e00f-7568e7b02e06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/paq2piq_standalone.py:46: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "  if backbone is 'resnet18':\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from paq2piq_standalone import *\n",
        "from torch.autograd import Variable\n",
        "import imageio\n",
        "import os\n",
        "import subprocess\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TH4fjg5-ZtDR"
      },
      "outputs": [],
      "source": [
        "IMAGE_NET_MEAN = [0.485, 0.456, 0.406]\n",
        "IMAGE_NET_STD = [0.229, 0.224, 0.225]\n",
        "\n",
        "\n",
        "class Transform:\n",
        "    def __init__(self):\n",
        "        # normalize = transforms.Normalize(mean=IMAGE_NET_MEAN, std=IMAGE_NET_STD)\n",
        "\n",
        "        self._train_transform = transforms.Compose(\n",
        "            [\n",
        "                transforms.ToTensor(),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        self._val_transform = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "    @property\n",
        "    def train_transform(self):\n",
        "        return self._train_transform\n",
        "\n",
        "    @property\n",
        "    def val_transform(self):\n",
        "        return self._val_transform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysGqpHqrZv5T",
        "outputId": "d48bb51a-fb95-4de8-eecb-a3d8d3c50e5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RoIPoolModel(\n",
              "  (body): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    (4): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (5): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (6): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (7): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (head): Sequential(\n",
              "    (0): AdaptiveConcatPool2d(\n",
              "      (ap): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "      (mp): AdaptiveMaxPool2d(output_size=(1, 1))\n",
              "    )\n",
              "    (1): Flatten(start_dim=1, end_dim=-1)\n",
              "    (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (3): Dropout(p=0.25, inplace=False)\n",
              "    (4): Linear(in_features=1024, out_features=512, bias=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (7): Dropout(p=0.5, inplace=False)\n",
              "    (8): Linear(in_features=512, out_features=1, bias=True)\n",
              "  )\n",
              "  (roi_pool): RoIPool(output_size=(2, 2), spatial_scale=0.03125)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "model_state = torch.load('RoIPoolModel.pth', map_location=lambda storage, loc: storage)\n",
        "model = RoIPoolModel()\n",
        "model.load_state_dict(model_state[\"model\"])\n",
        "model = model.to(device)\n",
        "transform = Transform().val_transform\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Attack training code"
      ],
      "metadata": {
        "id": "O6H09AWDDOjS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2QRTgkLXZyFE"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.autograd import Variable\n",
        "import cv2\n",
        "import numpy as np\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "from torch import optim\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "import imageio\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "import numpy as np\n",
        "from torchvision import transforms\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from torch.utils.data import Dataset\n",
        "from typing import Optional\n",
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "from torchvision import transforms\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SzWlMtbwZ2sl"
      },
      "outputs": [],
      "source": [
        "def center_crop(image):\n",
        "  center = image.shape[0] / 2, image.shape[1] / 2\n",
        "  if center[1] < 256 or center[0] < 256:\n",
        "    return cv2.resize(image, (256, 256))\n",
        "  x = center[1] - 128\n",
        "  y = center[0] - 128\n",
        "\n",
        "  return image[int(y):int(y+256), int(x):int(x+256)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TgtpuftUZ48B"
      },
      "outputs": [],
      "source": [
        "class MyCustomDataset(Dataset):\n",
        "    def __init__(self,\n",
        "                 path_gt,\n",
        "                 mode\n",
        "                ):\n",
        "\n",
        "        self._items = []\n",
        "        self._index = 0\n",
        "        self.mode = mode\n",
        "        if mode == 'train':\n",
        "          dir_img = sorted(os.listdir(path_gt))\n",
        "        else:\n",
        "          dir_img = sorted(os.listdir(path_gt))\n",
        "        img_pathes = dir_img\n",
        "\n",
        "        for img_path in img_pathes:\n",
        "          self._items.append((\n",
        "            os.path.join(path_gt, img_path)\n",
        "          ))\n",
        "        random.shuffle(self._items)\n",
        "\n",
        "    def __len__(self):\n",
        "      return len(self._items)\n",
        "\n",
        "    def next_data(self):\n",
        "      gt_path = self._items[self._index]\n",
        "      self._index += 1\n",
        "      if self._index == len(self._items):\n",
        "        self._index = 0\n",
        "        random.shuffle(self._items)\n",
        "\n",
        "      image = Image.open(gt_path).convert('RGB')\n",
        "      image = np.array(image).astype(np.float32)\n",
        "      image = center_crop(image)\n",
        "      #if self.mode=='train':\n",
        "      #  transformed = my_transform(image=image)\n",
        "      #  image = transformed[\"image\"]\n",
        "\n",
        "      image = image / 255.\n",
        "      image = transforms.ToTensor()(image)\n",
        "      #image = image.unsqueeze_(0)\n",
        "      y = image.to(device)\n",
        "      return y\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "      gt_path = self._items[index]\n",
        "      image = Image.open(gt_path).convert('RGB')\n",
        "      image = np.array(image).astype(np.float32)\n",
        "\n",
        "      image = center_crop(image)\n",
        "\n",
        "      image = image / 255.\n",
        "      image = transforms.ToTensor()(image)\n",
        "      y = image.to(device)\n",
        "      return y"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eps = 10/255"
      ],
      "metadata": {
        "id": "NjgGyfj-GB4t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I1XY97qfZ-wl"
      },
      "outputs": [],
      "source": [
        "lr = 0.001\n",
        "path_train = '/content/drive/MyDrive/metrics/train'\n",
        "path_test = '/content/drive/MyDrive/metrics/val'\n",
        "\n",
        "universal_noise = torch.zeros((1, 3, 256, 256)).to(device)\n",
        "universal_noise = Variable(universal_noise, requires_grad=True)\n",
        "optimizer = torch.optim.Adam([universal_noise], lr=lr)\n",
        "\n",
        "ds_train = MyCustomDataset(path_gt=path_train, mode='train')\n",
        "ds_val = MyCustomDataset(path_gt=path_test, mode='test')\n",
        "dl_train = DataLoader(ds_train, batch_size=4, shuffle=True)\n",
        "dl_val = DataLoader(ds_val, batch_size=4, shuffle=False)\n",
        "n_epoch = 10\n",
        "id = 0\n",
        "mean_train_loss = []\n",
        "mean_test_loss = []\n",
        "for epoch in range(n_epoch):\n",
        "  loss_list = []\n",
        "  for u in tqdm(range(len(dl_train))):\n",
        "    y = next(iter(dl_train))\n",
        "    res = y + universal_noise\n",
        "    res.data.clamp_(min=0.,max=1.)\n",
        "    loss = 1 - model(res).mean() / 100\n",
        "    loss_list.append(loss.item())\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    universal_noise.data.clamp_(min=-eps, max=eps)\n",
        "  print(epoch)\n",
        "  print('train loss = ' , np.array(loss_list).mean())\n",
        "  test_loss_list = []\n",
        "  with torch.no_grad():\n",
        "    for u in tqdm(range(len(dl_val))):\n",
        "      y = next(iter(dl_val))\n",
        "      res = y + universal_noise\n",
        "      res.data.clamp_(min=0.,max=1.)\n",
        "      loss = 1 - model(res).mean() / 100\n",
        "      test_loss_list.append(loss.item())\n",
        "  print('valid loss = ' , np.array(test_loss_list).mean())\n",
        "  res_image = (universal_noise + 0.5).data.clamp_(min=0, max=1)\n",
        "  res_img = (res_image.squeeze().data.cpu().numpy().transpose(1, 2, 0) * 255).astype('uint8')\n",
        "  imageio.imwrite(\"/content/drive/MyDrive/metrics/up_methods/df/paq2piq\"+f'/pic{epoch:03}.png', res_img)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}